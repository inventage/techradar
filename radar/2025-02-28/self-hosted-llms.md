---
title:    Self-hosted LLMs  
ring:     adopt  
quadrant: concepts-and-methods
featured: false
---

Ausgereifte Tools wie LM Studio, Ollama und Hugging Face erleichtern den Zugriff auf LLMs und ermöglichen den Betrieb lokal auf dem eigenen Rechner. Durch Optimierungen wie MLX für Mac, Quantisierung und eine stetig wachsende Open-Source-Community werden diese Modelle immer effizienter und benötigen weniger Speicher und Rechenleistung.

Der grösste Vorteil ist der Datenschutz. Self-hosted LLMs ermöglichen die Verarbeitung sensibler Daten, ohne sie an Dritte weiterzugeben.

Auch in diesem Jahr wollen wir Self-Hosted LLMs praxisnah testen. Wir wollen herausfinden wie gut sich Self-hosted LLMs in unsere Arbeitsabläufe integrieren lassen und wie sie im Vergleich zu kommerziellen Lösungen abschneiden.
