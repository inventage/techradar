---
title:    Self-Hosted-LLMs
ring:     trial
quadrant: platforms
tags:     [AI]
---

Ausgereifte Tools wie [LM Studio][lmstudio], [Ollama][ollama] und [Hugging Face][huggingFace] erleichtern die Installation und den Betrieb von LLMs lokal auf dem eigenen Rechner. Durch Optimierungen wie MLX für Mac, Quantisierung und eine stetig wachsende Open-Source-Community werden diese Modelle immer effizienter und benötigen weniger Speicher und Rechenleistung.

Der grösste Vorteil von Self-Hosted-LLMs ist der Datenschutz. Sie ermöglichen die Verarbeitung sensibler Daten, ohne diese an Dritte weiterzugeben.

Auch in diesem Jahr wollen wir Self-Hosted-LLMs praxisnah testen. Wir möchten herausfinden, wie gut sich Self-Hosted-LLMs in unsere Arbeitsabläufe integrieren lassen und wie sie im Vergleich zu kommerziellen Lösungen abschneiden.

[huggingFace]: https://huggingface.co/
[lmstudio]: https://lmstudio.ai
[ollama]: https://ollama.com/
